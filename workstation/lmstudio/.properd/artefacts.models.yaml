gguf__devstralsmall224binstruct2512: {"type":"llm","modelKey":"devstral-small-2-24b-instruct-2512","format":"gguf","displayName":"Devstral Small 2 24B Instruct 2512","publisher":"lmstudio-community","path":"lmstudio-community/Devstral-Small-2-24B-Instruct-2512-GGUF/Devstral-Small-2-24B-Instruct-2512-F16.gguf","sizeBytes":48032100576,"paramsString":"24B","architecture":"mistral3","quantization":{"name":"F16","bits":16},"vision":true,"trainedForToolUse":true,"maxContextLength":393216}
gguf__devstralsmall2507: {"type":"llm","modelKey":"devstral-small-2507","format":"gguf","displayName":"Devstral Small 2507","publisher":"lmstudio-community","path":"lmstudio-community/Devstral-Small-2507-GGUF/Devstral-Small-2507-Q4_K_M.gguf","sizeBytes":14333916160,"paramsString":"24B","architecture":"llama","quantization":{"name":"Q4_K_M","bits":4},"vision":false,"trainedForToolUse":true,"maxContextLength":131072}
gguf__gemma312bit: {"type":"llm","modelKey":"gemma-3-12b-it","format":"gguf","displayName":"Gemma 3 12B Instruct","publisher":"lmstudio-community","path":"lmstudio-community/gemma-3-12b-it-GGUF/gemma-3-12b-it-Q4_K_M.gguf","sizeBytes":8154775200,"paramsString":"12B","architecture":"gemma3","quantization":{"name":"Q4_K_M","bits":4},"vision":true,"trainedForToolUse":false,"maxContextLength":131072}
gguf__googlegemma312b: {"architecture":"gemma3","displayName":"Gemma 3 12B","format":"gguf","maxContextLength":131072,"modelKey":"google/gemma-3-12b","paramsString":"12B","path":"google/gemma-3-12b","sizeBytes":8154847769,"trainedForToolUse":false,"type":"llm","vision":true}
gguf__googlegemma31b: {"type":"llm","modelKey":"google/gemma-3-1b","format":"gguf","displayName":"Gemma 3 1B","publisher":"google","path":"google/gemma-3-1b","sizeBytes":720498528,"paramsString":"1B","architecture":"gemma3","quantization":{"name":"Q4_0","bits":4},"variants":["google/gemma-3-1b@q4_0"],"selectedVariant":"google/gemma-3-1b@q4_0","vision":false,"trainedForToolUse":false,"maxContextLength":32768}
gguf__googlegemma327b: {"architecture":"gemma3","displayName":"Gemma 3 27B","format":"gguf","maxContextLength":131072,"modelKey":"google/gemma-3-27b","paramsString":"27B","path":"google/gemma-3-27b","sizeBytes":16425207993,"trainedForToolUse":false,"type":"llm","vision":true}
gguf__googlegemma34b: {"type":"llm","modelKey":"google/gemma-3-4b","format":"gguf","displayName":"Gemma 3 4B","publisher":"google","path":"google/gemma-3-4b","sizeBytes":3341081486,"paramsString":"4B","architecture":"gemma3","quantization":{"name":"Q4_K_M","bits":4},"vision":true,"trainedForToolUse":false,"maxContextLength":131072}
gguf__googlegemma3ne4b: {"type":"llm","modelKey":"google/gemma-3n-e4b","format":"gguf","displayName":"Gemma 3n E4B","publisher":"google","path":"google/gemma-3n-e4b","sizeBytes":4237139272,"paramsString":"6.9B","architecture":"gemma3n","quantization":{"name":"Q4_K_M","bits":4},"vision":false,"trainedForToolUse":false,"maxContextLength":32768}
gguf__gptoss120b: {"type":"llm","modelKey":"gpt-oss-120b","format":"gguf","displayName":"OpenAI's gpt-oss 120B","publisher":"lmstudio-community","path":"lmstudio-community/gpt-oss-120b-GGUF/gpt-oss-120b-MXFP4-00001-of-00002.gguf","sizeBytes":63387345440,"paramsString":"120B","architecture":"gpt-oss","quantization":{"name":"MXFP4","bits":4},"vision":false,"trainedForToolUse":true,"maxContextLength":131072}
gguf__gptoss20b: {"architecture":"gpt-oss","displayName":"OpenAI's gpt-oss 20B","format":"gguf","maxContextLength":131072,"modelKey":"gpt-oss-20b","paramsString":"20B","path":"lmstudio-community/gpt-oss-20b-GGUF/gpt-oss-20b-MXFP4.gguf","sizeBytes":12109565632,"trainedForToolUse":true,"type":"llm","vision":false}
gguf__granite40hmicro: {"type":"llm","modelKey":"granite-4.0-h-micro","format":"gguf","displayName":"Granite 4.0 H Micro","publisher":"lmstudio-community","path":"lmstudio-community/granite-4.0-h-micro-GGUF/granite-4.0-h-micro-Q4_K_M.gguf","sizeBytes":1942564064,"paramsString":"3B","architecture":"granitehybrid","quantization":{"name":"Q4_K_M","bits":4},"vision":false,"trainedForToolUse":false,"maxContextLength":1048576}
gguf__granite40hsmall: {"type":"llm","modelKey":"granite-4.0-h-small","format":"gguf","displayName":"Granite 4.0 H Small","publisher":"lmstudio-community","path":"lmstudio-community/granite-4.0-h-small-GGUF/granite-4.0-h-small-Q8_0.gguf","sizeBytes":34264885504,"paramsString":"32B","architecture":"granitehybrid","quantization":{"name":"Q8_0","bits":8},"vision":false,"trainedForToolUse":true,"maxContextLength":1048576}
gguf__granite40htiny: {"type":"llm","modelKey":"granite-4.0-h-tiny","format":"gguf","displayName":"Granite 4.0 H Tiny","publisher":"lmstudio-community","path":"lmstudio-community/granite-4.0-h-tiny-GGUF/granite-4.0-h-tiny-Q4_K_M.gguf","sizeBytes":4230975936,"paramsString":"7B","architecture":"granitehybrid","quantization":{"name":"Q4_K_M","bits":4},"vision":false,"trainedForToolUse":false,"maxContextLength":1048576}
gguf__ibmgranite328b: {"architecture":"granite","displayName":"Granite 3.2 8B","format":"gguf","maxContextLength":131072,"modelKey":"ibm/granite-3.2-8b","paramsString":"8B","path":"ibm/granite-3.2-8b","publisher":"ibm","quantization":{"bits":4,"name":"Q4_K_M"},"sizeBytes":4942903724,"trainedForToolUse":false,"type":"llm","vision":false}
gguf__ibmgranite4htiny: {"type":"llm","modelKey":"ibm/granite-4-h-tiny","format":"gguf","displayName":"Granite 4 H Tiny","publisher":"ibm","path":"ibm/granite-4-h-tiny","sizeBytes":4231029544,"paramsString":"7B","architecture":"granitehybrid","quantization":{"name":"Q4_K_M","bits":4},"variants":["ibm/granite-4-h-tiny@q4_k_m"],"selectedVariant":"ibm/granite-4-h-tiny@q4_k_m","vision":false,"trainedForToolUse":true,"maxContextLength":1048576}
gguf__ibmgranitegranite40hsmall: {"type":"llm","modelKey":"ibm-granite/granite-4.0-h-small","format":"gguf","displayName":"Granite 4.0 H Small","publisher":"ibm-granite","path":"ibm-granite/granite-4.0-h-small-GGUF/granite-4.0-h-small-f16.gguf","sizeBytes":64446180288,"architecture":"granitehybrid","quantization":{"name":"F16","bits":16},"vision":false,"trainedForToolUse":true,"maxContextLength":1048576}
gguf__lfm2512binstruct: {"type":"llm","modelKey":"lfm2.5-1.2b-instruct","format":"gguf","displayName":"LFM2.5 1.2B Instruct","publisher":"LiquidAI","path":"LiquidAI/LFM2.5-1.2B-Instruct/LFM2.5-1.2B-Instruct-BF16.gguf","sizeBytes":2343326528,"paramsString":"1.2B","architecture":"lfm2","quantization":{"name":"BF16","bits":16},"vision":false,"trainedForToolUse":false,"maxContextLength":128000}
gguf__lfm2512bthinking@f16: {"type":"llm","modelKey":"lfm2.5-1.2b-thinking@f16","format":"gguf","displayName":"LFM2.5 1.2B Thinking","publisher":"LiquidAI","path":"LiquidAI/LFM2.5-1.2B-Thinking-GGUF/LFM2.5-1.2B-Thinking-F16.gguf","sizeBytes":2343326720,"paramsString":"1.2B","architecture":"lfm2","quantization":{"name":"F16","bits":16},"vision":false,"trainedForToolUse":true,"maxContextLength":128000}
gguf__lfm2512bthinking@q8_0: {"type":"llm","modelKey":"lfm2.5-1.2b-thinking@q8_0","format":"gguf","displayName":"LFM2.5 1.2B Thinking","publisher":"LiquidAI","path":"LiquidAI/LFM2.5-1.2B-Thinking-GGUF/LFM2.5-1.2B-Thinking-Q8_0.gguf","sizeBytes":1246254080,"paramsString":"1.2B","architecture":"lfm2","quantization":{"name":"Q8_0","bits":8},"vision":false,"trainedForToolUse":true,"maxContextLength":128000}
gguf__lfm25vl16b: {"type":"llm","modelKey":"lfm2.5-vl-1.6b","format":"gguf","displayName":"LFM2.5 VL 1.6B","publisher":"LiquidAI","path":"LiquidAI/LFM2.5-VL-1.6B-GGUF/LFM2.5-VL-1.6B-F16.gguf","sizeBytes":3197321056,"paramsString":"1.6B","architecture":"lfm2","quantization":{"name":"F16","bits":16},"vision":true,"trainedForToolUse":true,"maxContextLength":128000}
gguf__lfm25vl16b@bf16: {"type":"llm","modelKey":"lfm2.5-vl-1.6b@bf16","format":"gguf","displayName":"LFM2.5 VL 1.6B","publisher":"LiquidAI","path":"LiquidAI/LFM2.5-VL-1.6B-GGUF/LFM2.5-VL-1.6B-BF16.gguf","sizeBytes":3197321056,"paramsString":"1.6B","architecture":"lfm2","quantization":{"name":"BF16","bits":16},"vision":false,"trainedForToolUse":false,"maxContextLength":128000}
gguf__lfm25vl16b@f16: {"type":"llm","modelKey":"lfm2.5-vl-1.6b@f16","format":"gguf","displayName":"LFM2.5 VL 1.6B","publisher":"LiquidAI","path":"LiquidAI/LFM2.5-VL-1.6B-GGUF/LFM2.5-VL-1.6B-F16.gguf","sizeBytes":3197321056,"paramsString":"1.6B","architecture":"lfm2","quantization":{"name":"F16","bits":16},"vision":false,"trainedForToolUse":false,"maxContextLength":128000}
gguf__liquidlfm212b: {"architecture":"lfm2","displayName":"Lfm2 1.2B","format":"gguf","maxContextLength":128000,"modelKey":"liquid/lfm2-1.2b","paramsString":"1.2B","path":"liquid/lfm2-1.2b","sizeBytes":1246327741,"trainedForToolUse":false,"type":"llm","vision":false}
gguf__liquidlfm2512b: {"type":"llm","modelKey":"liquid/lfm2.5-1.2b","format":"gguf","displayName":"Lfm2.5 1.2B","publisher":"liquid","path":"liquid/lfm2.5-1.2b","sizeBytes":730973120,"paramsString":"1.2B","architecture":"lfm2","quantization":{"name":"Q4_K_M","bits":4},"vision":false,"trainedForToolUse":false,"maxContextLength":128000}
gguf__llama4scout17b16einstruct: {"type":"llm","modelKey":"llama-4-scout-17b-16e-instruct","format":"gguf","displayName":"Llama 4 Scout 17B 16E Instruct","publisher":"lmstudio-community","path":"lmstudio-community/Llama-4-Scout-17B-16E-Instruct-GGUF/Llama-4-Scout-17B-16E-Instruct-Q8_0-00001-of-00003.gguf","sizeBytes":113399124512,"paramsString":"17B","architecture":"llama4","quantization":{"name":"Q8_0","bits":8},"vision":false,"trainedForToolUse":true,"maxContextLength":10485760}
gguf__lmstudiocommunitygranite40hsmall: {"type":"llm","modelKey":"lmstudio-community/granite-4.0-h-small","format":"gguf","displayName":"Granite 4.0 H Small","publisher":"lmstudio-community","path":"lmstudio-community/granite-4.0-h-small-GGUF/granite-4.0-h-small-Q8_0.gguf","sizeBytes":34264885504,"paramsString":"32B","architecture":"granitehybrid","quantization":{"name":"Q8_0","bits":8},"vision":false,"trainedForToolUse":true,"maxContextLength":1048576}
gguf__metallama3370b: {"architecture":"llama","displayName":"Llama 3.3 70B","format":"gguf","maxContextLength":131072,"modelKey":"meta/llama-3.3-70b","paramsString":"70B","path":"meta/llama-3.3-70b","sizeBytes":42520506023,"trainedForToolUse":true,"type":"llm","vision":false}
gguf__microsoftphi4: {"architecture":"phi3","displayName":"Phi 4","format":"gguf","maxContextLength":16384,"modelKey":"microsoft/phi-4","paramsString":"15B","path":"microsoft/phi-4","sizeBytes":9053136497,"trainedForToolUse":false,"type":"llm","vision":false}
gguf__microsoftphi4minireasoning: {"type":"llm","modelKey":"microsoft/phi-4-mini-reasoning","format":"gguf","displayName":"Phi 4 Mini Reasoning","publisher":"microsoft","path":"microsoft/phi-4-mini-reasoning","sizeBytes":4084634309,"paramsString":"3B","architecture":"phi3","quantization":{"name":"Q8_0","bits":8},"vision":false,"trainedForToolUse":false,"maxContextLength":131072}
gguf__microsoftphi4reasoningplus: {"architecture":"phi3","displayName":"Phi 4 Reasoning Plus","format":"gguf","maxContextLength":32768,"modelKey":"microsoft/phi-4-reasoning-plus","paramsString":"15B","path":"microsoft/phi-4-reasoning-plus","sizeBytes":9053139092,"trainedForToolUse":false,"type":"llm","vision":false}
gguf__ministral314breasoning2512: {"type":"llm","modelKey":"ministral-3-14b-reasoning-2512","format":"gguf","displayName":"Ministral 3 14B Reasoning 2512","publisher":"lmstudio-community","path":"lmstudio-community/Ministral-3-14B-Reasoning-2512-GGUF/Ministral-3-14B-Reasoning-2512-Q8_0.gguf","sizeBytes":15237362784,"paramsString":"14B","architecture":"mistral3","quantization":{"name":"Q8_0","bits":8},"vision":true,"trainedForToolUse":true,"maxContextLength":262144}
gguf__ministral314breasoning2512@q4_k_m: {"type":"llm","modelKey":"ministral-3-14b-reasoning-2512@q4_k_m","format":"gguf","displayName":"Ministral 3 14B Reasoning 2512","publisher":"lmstudio-community","path":"lmstudio-community/Ministral-3-14B-Reasoning-2512-GGUF/Ministral-3-14B-Reasoning-2512-Q4_K_M.gguf","sizeBytes":9117119584,"paramsString":"14B","architecture":"mistral3","quantization":{"name":"Q4_K_M","bits":4},"vision":true,"trainedForToolUse":true,"maxContextLength":262144}
gguf__ministral314breasoning2512@q8_0: {"type":"llm","modelKey":"ministral-3-14b-reasoning-2512@q8_0","format":"gguf","displayName":"Ministral 3 14B Reasoning 2512","publisher":"lmstudio-community","path":"lmstudio-community/Ministral-3-14B-Reasoning-2512-GGUF/Ministral-3-14B-Reasoning-2512-Q8_0.gguf","sizeBytes":15237362784,"paramsString":"14B","architecture":"mistral3","quantization":{"name":"Q8_0","bits":8},"vision":true,"trainedForToolUse":true,"maxContextLength":262144}
gguf__ministral38binstruct2512: {"type":"llm","modelKey":"ministral-3-8b-instruct-2512","format":"gguf","displayName":"Ministral 3 8B Instruct 2512","publisher":"mistralai","path":"mistralai/Ministral-3-8B-Instruct-2512-GGUF/Ministral-3-8B-Instruct-2512-Q8_0.gguf","sizeBytes":9029392800,"paramsString":"8B","architecture":"mistral3","quantization":{"name":"Q8_0","bits":8},"vision":false,"trainedForToolUse":true,"maxContextLength":262144}
gguf__mistralaidevstralsmall22512: {"type":"llm","modelKey":"mistralai/devstral-small-2-2512","format":"gguf","displayName":"Devstral Small 2 2512","publisher":"mistralai","path":"mistralai/devstral-small-2-2512","sizeBytes":13279367590,"paramsString":"24B","architecture":"mistral3","quantization":{"name":"Q3_K_L","bits":3},"variants":["mistralai/devstral-small-2-2512@q3_k_l"],"selectedVariant":"mistralai/devstral-small-2-2512@q3_k_l","vision":true,"trainedForToolUse":true,"maxContextLength":393216}
gguf__mistralaiministral314breasoning: {"type":"llm","modelKey":"mistralai/ministral-3-14b-reasoning","format":"gguf","displayName":"Ministral 3 14B Reasoning","publisher":"mistralai","path":"mistralai/ministral-3-14b-reasoning","sizeBytes":9117141778,"paramsString":"14B","architecture":"mistral3","quantization":{"name":"Q4_K_M","bits":4},"vision":true,"trainedForToolUse":false,"maxContextLength":262144}
gguf__mistralaiministral33b: {"type":"llm","modelKey":"mistralai/ministral-3-3b","format":"gguf","displayName":"Ministral 3 3B","publisher":"mistralai","path":"mistralai/ministral-3-3b","sizeBytes":4491998767,"paramsString":"3B","architecture":"mistral3","quantization":{"name":"Q8_0","bits":8},"vision":true,"trainedForToolUse":false,"maxContextLength":262144}
gguf__nvidianemotron3nano30ba3b: {"type":"llm","modelKey":"nvidia-nemotron-3-nano-30b-a3b","format":"gguf","displayName":"NVIDIA Nemotron 3 Nano 30B A3B","publisher":"lmstudio-community","path":"lmstudio-community/NVIDIA-Nemotron-3-Nano-30B-A3B-GGUF/NVIDIA-Nemotron-3-Nano-30B-A3B-Q4_K_M.gguf","sizeBytes":24515129632,"paramsString":"30B","architecture":"nemotron_h_moe","quantization":{"name":"Q4_K_M","bits":4},"vision":false,"trainedForToolUse":true,"maxContextLength":1048576}
gguf__nvidianemotron3nano30ba3b@f16: {"type":"llm","modelKey":"nvidia-nemotron-3-nano-30b-a3b@f16","format":"gguf","displayName":"NVIDIA Nemotron 3 Nano 30B A3B","publisher":"lmstudio-community","path":"lmstudio-community/NVIDIA-Nemotron-3-Nano-30B-A3B-GGUF/NVIDIA-Nemotron-3-Nano-30B-A3B-F16-00001-of-00002.gguf","sizeBytes":63181504480,"paramsString":"30B","architecture":"nemotron_h_moe","quantization":{"name":"F16","bits":16},"vision":false,"trainedForToolUse":true,"maxContextLength":1048576}
gguf__nvidianemotron3nano30ba3b@q8_0: {"type":"llm","modelKey":"nvidia-nemotron-3-nano-30b-a3b@q8_0","format":"gguf","displayName":"NVIDIA Nemotron 3 Nano 30B A3B","publisher":"lmstudio-community","path":"lmstudio-community/NVIDIA-Nemotron-3-Nano-30B-A3B-GGUF/NVIDIA-Nemotron-3-Nano-30B-A3B-Q8_0.gguf","sizeBytes":33585495328,"paramsString":"30B","architecture":"nemotron_h_moe","quantization":{"name":"Q8_0","bits":8},"vision":false,"trainedForToolUse":true,"maxContextLength":1048576}
gguf__nvidianemotron3nano: {"type":"llm","modelKey":"nvidia/nemotron-3-nano","format":"gguf","displayName":"Nemotron 3 Nano","publisher":"nvidia","path":"nvidia/nemotron-3-nano","sizeBytes":24515232077,"paramsString":"30B","architecture":"nemotron_h_moe","quantization":{"name":"Q4_K_M","bits":4},"variants":["nvidia/nemotron-3-nano@q4_k_m","nvidia/nemotron-3-nano@f16"],"selectedVariant":"nvidia/nemotron-3-nano@q4_k_m","vision":false,"trainedForToolUse":true,"maxContextLength":1048576}
gguf__openaigptoss120b: {"type":"llm","modelKey":"openai/gpt-oss-120b","format":"gguf","displayName":"OpenAI's gpt-oss 120B","path":"openai/gpt-oss-120b","sizeBytes":63387444066,"paramsString":"120B","architecture":"gpt-oss","vision":false,"trainedForToolUse":true,"maxContextLength":131072}
gguf__openaigptoss20b: {"architecture":"gpt-oss","displayName":"OpenAI's gpt-oss 20B","format":"gguf","maxContextLength":131072,"modelKey":"openai/gpt-oss-20b","paramsString":"20B","path":"openai/gpt-oss-20b","sizeBytes":12109664245,"trainedForToolUse":true,"type":"llm","vision":false}
gguf__phi4: {"type":"llm","modelKey":"phi-4","format":"gguf","displayName":"Phi 4","publisher":"lmstudio-community","path":"lmstudio-community/phi-4-GGUF/phi-4-Q4_K_M.gguf","sizeBytes":9053114560,"paramsString":"15B","architecture":"phi3","quantization":{"name":"Q4_K_M","bits":4},"vision":false,"trainedForToolUse":false,"maxContextLength":16384}
gguf__textembeddingnomicembedtextv15: {"architecture":"nomic-bert","displayName":"Nomic Embed Text v1.5","format":"gguf","maxContextLength":2048,"modelKey":"text-embedding-nomic-embed-text-v1.5","path":"nomic-ai/nomic-embed-text-v1.5-GGUF/nomic-embed-text-v1.5.Q4_K_M.gguf","sizeBytes":84106624,"type":"embedding"}
safetensors__googlegemma312b: {"architecture":"gemma3","displayName":"Gemma 3 12B","format":"safetensors","maxContextLength":131072,"modelKey":"google/gemma-3-12b","path":"google/gemma-3-12b","publisher":"google","quantization":{"bits":4,"name":"4bit"},"sizeBytes":8068097455,"trainedForToolUse":false,"type":"llm","vision":true}
safetensors__googlegemma34b: {"architecture":"gemma3","displayName":"Gemma 3 4B","format":"safetensors","maxContextLength":131072,"modelKey":"google/gemma-3-4b","path":"google/gemma-3-4b","publisher":"google","quantization":{"bits":4,"name":"4bit"},"sizeBytes":3034755901,"trainedForToolUse":false,"type":"llm","vision":true}
safetensors__googlegemma3ne4b: {"architecture":"gemma3n","displayName":"Gemma 3n E4B","format":"safetensors","maxContextLength":32768,"modelKey":"google/gemma-3n-e4b","path":"google/gemma-3n-e4b","publisher":"google","quantization":{"bits":4,"name":"4bit"},"sizeBytes":5858917459,"trainedForToolUse":false,"type":"llm","vision":true}
safetensors__microsoftphi4minireasoning: {"architecture":"phi3","displayName":"Phi 4 Mini Reasoning","format":"safetensors","maxContextLength":131072,"modelKey":"microsoft/phi-4-mini-reasoning","path":"microsoft/phi-4-mini-reasoning","publisher":"microsoft","quantization":{"bits":4,"name":"4bit"},"sizeBytes":2180017503,"trainedForToolUse":false,"type":"llm","vision":false}
safetensors__microsoftphi4reasoningplus: {"architecture":"phi3","displayName":"Phi 4 Reasoning Plus","format":"safetensors","maxContextLength":32768,"modelKey":"microsoft/phi-4-reasoning-plus","path":"microsoft/phi-4-reasoning-plus","publisher":"microsoft","quantization":{"bits":4,"name":"4bit"},"sizeBytes":8256411728,"trainedForToolUse":false,"type":"llm","vision":false}
gguf__devstral2123binstruct2512: {"type":"llm","modelKey":"devstral-2-123b-instruct-2512","format":"gguf","displayName":"Devstral 2 123B Instruct 2512","publisher":"lmstudio-community","path":"lmstudio-community/Devstral-2-123B-Instruct-2512-GGUF/Devstral-2-123B-Instruct-2512-Q4_K_M-00001-of-00002.gguf","sizeBytes":74897652896,"paramsString":"123B","architecture":"llama","quantization":{"name":"Q4_K_M","bits":4},"vision":false,"trainedForToolUse":true,"maxContextLength":262144}
gguf__gemma327bit: {"type":"llm","modelKey":"gemma-3-27b-it","format":"gguf","displayName":"Gemma 3 27B Instruct","publisher":"ggml-org","path":"ggml-org/gemma-3-27b-it-GGUF/gemma-3-27b-it-Q8_0.gguf","sizeBytes":29565344032,"paramsString":"27B","architecture":"gemma3","quantization":{"name":"Q8_0","bits":8},"vision":true,"trainedForToolUse":false,"maxContextLength":131072}
gguf__lfm224ba2b@f16: {"type":"llm","modelKey":"lfm2-24b-a2b@f16","format":"gguf","displayName":"LFM2 24B A2B","publisher":"LiquidAI","path":"LiquidAI/LFM2-24B-A2B-GGUF/LFM2-24B-A2B-F16.gguf","sizeBytes":47700397344,"paramsString":"64x1.3B","architecture":"lfm2moe","quantization":{"name":"F16","bits":16},"vision":false,"trainedForToolUse":true,"maxContextLength":128000}
gguf__lfm224ba2b@q4_0: {"type":"llm","modelKey":"lfm2-24b-a2b@q4_0","format":"gguf","displayName":"LFM2 24B A2B","publisher":"LiquidAI","path":"LiquidAI/LFM2-24B-A2B-GGUF/LFM2-24B-A2B-Q4_0.gguf","sizeBytes":13467405600,"paramsString":"64x1.3B","architecture":"lfm2moe","quantization":{"name":"Q4_0","bits":4},"vision":false,"trainedForToolUse":true,"maxContextLength":128000}
gguf__lfm224ba2b@q8_0: {"type":"llm","modelKey":"lfm2-24b-a2b@q8_0","format":"gguf","displayName":"LFM2 24B A2B","publisher":"LiquidAI","path":"LiquidAI/LFM2-24B-A2B-GGUF/LFM2-24B-A2B-Q8_0.gguf","sizeBytes":25351965984,"paramsString":"64x1.3B","architecture":"lfm2moe","quantization":{"name":"Q8_0","bits":8},"vision":false,"trainedForToolUse":true,"maxContextLength":128000}
gguf__ministral33binstruct2512: {"type":"llm","modelKey":"ministral-3-3b-instruct-2512","format":"gguf","displayName":"Ministral 3 3B Instruct 2512","publisher":"lmstudio-community","path":"lmstudio-community/Ministral-3-3B-Instruct-2512-GGUF/Ministral-3-3B-Instruct-2512-Q8_0.gguf","sizeBytes":4491977024,"paramsString":"3B","architecture":"mistral3","quantization":{"name":"Q8_0","bits":8},"vision":true,"trainedForToolUse":true,"maxContextLength":262144}
gguf__lfm2512bthinking: {"type":"llm","modelKey":"lfm2.5-1.2b-thinking","format":"gguf","displayName":"LFM2.5 1.2B Thinking","publisher":"LiquidAI","path":"LiquidAI/LFM2.5-1.2B-Thinking-GGUF/LFM2.5-1.2B-Thinking-F16.gguf","sizeBytes":2343326720,"paramsString":"1.2B","architecture":"lfm2","quantization":{"name":"F16","bits":16},"vision":false,"trainedForToolUse":true,"maxContextLength":128000}
gguf__gemma3ne4bittext: {"type":"llm","modelKey":"gemma-3n-e4b-it-text","format":"gguf","displayName":"Gemma 3n E4B Instruct","publisher":"lmstudio-community","path":"lmstudio-community/gemma-3n-E4B-it-text-GGUF/gemma-3n-E4B-it-Q8_0.gguf","sizeBytes":7353291936,"paramsString":"6.9B","architecture":"gemma3n","quantization":{"name":"Q8_0","bits":8},"vision":false,"trainedForToolUse":false,"maxContextLength":32768}
gguf__lfm2512binstruct@f16: {"type":"llm","modelKey":"lfm2.5-1.2b-instruct@f16","format":"gguf","displayName":"LFM2.5 1.2B Instruct","publisher":"LiquidAI","path":"LiquidAI/LFM2.5-1.2B-Instruct-GGUF/LFM2.5-1.2B-Instruct-F16.gguf","sizeBytes":2343326528,"paramsString":"1.2B","architecture":"lfm2","quantization":{"name":"F16","bits":16},"vision":false,"trainedForToolUse":true,"maxContextLength":128000}
gguf__lfm2512binstruct@bf16: {"type":"llm","modelKey":"lfm2.5-1.2b-instruct@bf16","format":"gguf","displayName":"LFM2.5 1.2B Instruct","publisher":"LiquidAI","path":"LiquidAI/LFM2.5-1.2B-Instruct/LFM2.5-1.2B-Instruct-BF16.gguf","sizeBytes":2343326528,"paramsString":"1.2B","architecture":"lfm2","quantization":{"name":"BF16","bits":16},"vision":false,"trainedForToolUse":true,"maxContextLength":128000}
